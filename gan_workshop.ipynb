{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPRg9uhAPRz2+5cRk3rerm5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditigoswami3/MDAI/blob/main/gan_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lfH8TaAqLfnc",
        "outputId": "b7281497-ef4d-4bd6-fe5a-56ad8eb66ec8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 173
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device =\"cuda\""
      ],
      "metadata": {
        "id": "tlqXd4NLLke4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "TRGYR_mrLn3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSpkU3QbLu18",
        "outputId": "4e3e58bb-a434-43d4-d75c-51eb7ac07ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVJhx4t6Lx0s",
        "outputId": "df78d32f-f2a1-420f-b294-e3c3f84026fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len\n",
        "(\n",
        "X_train\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8us-mZXBL1-B",
        "outputId": "131da666-3d81-4dae-db50-3c2ce97c3e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train\n",
        "[\n",
        "90\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuMpJGZOL6HX",
        "outputId": "861f8384-5d2c-4d93-a551-0c15bba67b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[90]"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape\n",
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2VnPcqfL867",
        "outputId": "eaa3e142-cbe4-4648-a18f-b1a870a47ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = np.random.randint(0,60000)\n",
        "print(i)\n",
        "print(y_train[i])\n",
        "plt.imshow(X_train[i],cmap =\"gray\")\n",
        "plt.title(\"Img at index i\")\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "aqT2sC-kMAxF",
        "outputId": "371fe961-6f2c-4e2c-af37-e1999bcc2d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12343\n",
            "4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 401);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 181
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],28,28,1).astype('float32')"
      ],
      "metadata": {
        "id": "HWH7use7MJfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p50GjLbSMbjt",
        "outputId": "7228c227-9526-4bc7-b1bd-5389ad21f392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].min(), X_train[0].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_J1GM_QMveA",
        "outputId": "cdf61301-20b9-4a70-ba31-e9a5c8046b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 255.0)"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = (X_train-127.5)/ 127.5"
      ],
      "metadata": {
        "id": "vrCluCocMyBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].min(), X_train[0].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCBrCe4cM0wu",
        "outputId": "8579bd8c-6fd1-4d9d-ab79-7583912d642d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_size = 60000\n",
        "batch_size = 256\n",
        "buffer_size/batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu8mDBdaM3Lh",
        "outputId": "6cdb9984-339d-4462-c3b2-23837ad619d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "234.375"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcI1mGT9M8fo",
        "outputId": "33d2b30e-aaae-439c-9bb6-818d418cd1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7b3XNxpNA7p",
        "outputId": "b35df937-96b7-49e8-e8be-4d95fc80afef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg2k4232NM5c",
        "outputId": "4b55242b-c31a-451d-c8e0-b17915a883cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "\n",
        "  #Step 1:\n",
        "  network = tf.keras.Sequential()     # default class to buid neural network using Tenserflow\n",
        "\n",
        "  #Step 2: adding layers to dense NN\n",
        "  network.add(layers.Dense(units=7*7*256 , use_bias = False, input_shape = (100,)))\n",
        "\n",
        "  #step 3: apply normalization calc\n",
        "  network.add(layers.BatchNormalization())\n",
        "\n",
        "  #step 4: Add Activation layer\n",
        "  network.add(layers.LeakyReLU())\n",
        "\n",
        "  #step 5: Reshape for next layer\n",
        "  network.add(layers.Reshape((7,7,256)))\n",
        "\n",
        "  #step 6: to upscale cnn layer using Conv2DTranspose\n",
        "\n",
        "  #7*7*128 (Hidden layer 1)\n",
        "  network.add(layers.Conv2DTranspose(filters=128, kernel_size=(5,5), padding='same', use_bias = False ))\n",
        "  network.add(layers.BatchNormalization())\n",
        "  network.add(layers.LeakyReLU())\n",
        "\n",
        "  #14*14*64\n",
        "  network.add(layers.Conv2DTranspose(filters=64, kernel_size=(5,5), padding ='same', strides=(2,2), use_bias = False))\n",
        "  network.add(layers.BatchNormalization())\n",
        "  network.add(layers.LeakyReLU())\n",
        "\n",
        "  #28*28*1 (output layer )\n",
        "  network.add(layers.Conv2DTranspose(filters=1 , kernel_size=(5,5), padding ='same', strides=(2,2), use_bias = True, activation = 'tanh'))\n",
        "\n",
        "  network.summary()\n",
        "\n",
        "  return network"
      ],
      "metadata": {
        "id": "vpEjb8jZNGWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DbXQa5sQj1td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator= build_generator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdwrloCpNclK",
        "outputId": "a82d369d-2f67-4b7b-efc2-b3321a0e5162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 12544)             1254400   \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 12544)             50176     \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_19 (LeakyReLU)  (None, 12544)             0         \n",
            "                                                                 \n",
            " reshape_4 (Reshape)         (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_12 (Conv2  (None, 7, 7, 128)         819200    \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 7, 7, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_20 (LeakyReLU)  (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_13 (Conv2  (None, 14, 14, 64)        204800    \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 14, 14, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_21 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_14 (Conv2  (None, 28, 28, 1)         1601      \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2330945 (8.89 MB)\n",
            "Trainable params: 2305473 (8.79 MB)\n",
            "Non-trainable params: 25472 (99.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7mnwjbpfwi1",
        "outputId": "199501d0-bcd4-4978-eb70-6d7197de26c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'dense_7_input')>"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise=tf.random.normal([1,100])\n",
        "noise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTV1c_5Rj5zT",
        "outputId": "a4e6ac3b-c52e-4a2c-9844-30aaa8a8e36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
              "array([[-0.2287714 , -0.31625196,  2.9310944 , -1.2063259 ,  0.625092  ,\n",
              "         0.28018674,  0.31611195,  1.2022496 ,  1.8707796 ,  0.49548516,\n",
              "        -0.4916546 , -0.55053   , -1.4741819 ,  0.33218798, -0.43651715,\n",
              "        -1.4169377 , -0.05463019, -0.04784762, -0.4422113 ,  1.7975674 ,\n",
              "        -0.51864535, -0.61455667, -1.639613  ,  0.5819032 , -1.1375742 ,\n",
              "        -0.54847145,  1.582125  ,  0.3729733 ,  0.6913867 , -0.85540384,\n",
              "        -0.93198323, -0.5434792 , -0.6106521 ,  0.2975674 , -0.32081535,\n",
              "         0.07619406, -0.6940826 , -0.1565633 ,  0.67402476, -1.7259072 ,\n",
              "        -1.2437484 ,  0.18101308, -0.4505032 , -1.8014352 , -1.6747906 ,\n",
              "         0.7247924 , -0.32016638,  0.05696648, -0.55709106, -0.3774761 ,\n",
              "        -0.8958403 ,  1.6334938 ,  1.6844656 ,  0.8916119 , -0.49125496,\n",
              "        -0.9492794 , -1.3441806 , -0.3790429 ,  0.1245248 , -1.0088501 ,\n",
              "         2.4059184 ,  0.38320103, -1.8354385 , -1.1831685 ,  1.361731  ,\n",
              "        -0.09568398,  1.0029503 , -0.7837019 , -1.408075  ,  0.62518567,\n",
              "         0.92850167,  1.0947636 ,  1.1772817 , -0.6697235 ,  1.6308807 ,\n",
              "         0.8519776 , -1.637346  , -0.0875551 ,  1.0667611 , -0.7645031 ,\n",
              "         1.6106894 ,  1.2091337 ,  1.6409106 , -0.19649893, -0.09046099,\n",
              "        -0.44504508,  0.16452365, -0.48566493, -0.6643893 ,  0.28135023,\n",
              "         0.9199142 ,  0.20198543, -0.67621934,  0.6123332 , -0.02840508,\n",
              "         0.94331026,  0.16747658, -1.8888812 ,  1.8503243 , -1.7158395 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_image = generator(noise, training=False)"
      ],
      "metadata": {
        "id": "n4rTcXEekDKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4SeZKX4lUtV",
        "outputId": "38b780a4-b3e3-4756-a416-cdea88e56f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 28, 28, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(generated_image[0, :,:,0], cmap=\"gray\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "cqSfZeB8lkpN",
        "outputId": "7ff74422-dafd-4090-a4e1-d60a627c99c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a68d7e499c0>"
            ]
          },
          "metadata": {},
          "execution_count": 197
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAorUlEQVR4nO3de3CV9Z3H8U+A5CRAckIScpMAAbkohCi3LKKIQoHouqJsV6ttsduB0Q2OSKs2Ha/VTrZ0xrV2WZl2dmVrBS9dkZF1US6SqCUoETbFKoYY5JogYE7IPZBn/2DIGuVyvo8JvyS+XzNnRpLfh+eXJ0/y8XDO+Z4Iz/M8AQBwgfVyvQEAwLcTBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADAiT6uN/BVra2tOnjwoGJjYxUREeF6OwAAI8/zdPz4caWnp6tXr7Pfz+lyBXTw4EFlZGS43gYA4Bvat2+fBg0adNbPd7kCio2NlSQ9+OCDio6ODjsXGRlpPtaFvIfV2Nhozli+/tNiYmLMmX379pkzkpSSkmLOHDlyxJwZPHiwOXP06FFzRpL69LH/SPj53vbu3ducOXTokDlz0UUXmTN+9evXz5yprKw0ZwYMGGDOnDhxwpyRpGAwaM7s3r3bnBk2bJg58/nnn5szkjRw4EBz5osvvjCtb2xsVEFBQdvv87PptAJatmyZfv3rX6uyslLZ2dn67W9/q8mTJ583d7oUoqOjTb+Ao6KizHvs6v/E56dM/GQCgYA54/dYF6pU/RxH8ldAfvgpID/fJ7/nwY+ufD20tLSYM36P5ef7dCGvcT/Hamho8HWs8/2O7ZQnIbz44otasmSJHnnkEX3wwQfKzs7W7Nmzdfjw4c44HACgG+qUAnryySe1YMEC/ehHP9Kll16q5cuXq2/fvvqP//iPzjgcAKAb6vACam5uVklJiWbOnPn/B+nVSzNnztSWLVu+tr6pqUk1NTXtbgCAnq/DC+jIkSM6efLk1x6gTklJOeMDjgUFBQoGg203ngEHAN8Ozl+Imp+fr1Ao1Hbz+4wsAED30uFP+UlKSlLv3r1VVVXV7uNVVVVKTU392vpAIOD7WVgAgO6rw+8BRUVFacKECdq4cWPbx1pbW7Vx40ZNmTKlow8HAOimOuVFD0uWLNH8+fM1ceJETZ48WU899ZTq6ur0ox/9qDMOBwDohjqlgG655RZ9/vnnevjhh1VZWanLLrtM69at8/XKeQBAzxTheZ7nehNfVlNTo2AwqF/96lemV+wmJyebj+V3XEt6ero5U1tba84cO3bMnNmzZ48542cMiOTvldh+RpuUl5ebM37GwkhS//79zRk/o4Lef/99c2bs2LHmjN/JDn6u8eeff96c8fM1+fkelZSUmDOSv2s8ISHBnDnfyJozCYVC5ozkbyrEuQaKnkljY6N+9rOfKRQKKS4u7ux/r3knAAB0AAoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA40SnTsDtCZGSkIiMjw15fU1NjPobfQY2ffPKJOdO3b19zprW11Zzx8+Z+8fHx5owknThxwpxZv369OXPppZeaM01NTeaMJA0dOtSc+eqbL4ajsbHRnHnjjTfMmYkTJ5ozklRUVGTODBw40Jz58MMPzZnvfOc75oyfoaKSv++tdXCn5G94rp/feZK//Vmv13B//rgHBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACe67DTsXr16maa27tu3rxN3096xY8fMmaysLHPGz8Tk7Oxsc+bw4cPmjCTFxMSYM36mgodCIXPm5ptvNmckadWqVebMnDlzzBk/k6Pffvttc+b48ePmjCTNnTvXnKmsrDRn3n//fXPmd7/7nTnzgx/8wJyRpObmZnMmNjbWnPFzHvr372/OSP4m5lvPQ0NDQ1jruAcEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE502WGkTU1NioiICHt9MBg0H6Ours6ckaTIyEhzZu3atebM6NGjzZmLL77YnPnkk0/MGUnq08d++Vx00UXmzPDhw82ZN99805yR/A1m3bp1qzmTlpZmzmzbts2cSUpKMmckKS4uzpwpKyszZ1JTU82Zfv36mTMlJSXmjOTv+7R9+3ZzJjEx0Zzx+/vL8nv1NOsQ4XCPwT0gAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCiyw4jjYyMVFRUVNjrrcPyJGnQoEHmjCS1traaM1lZWebMvn37zJmGhgZzZtiwYeaMJA0cONCcCQQC5kxxcbE588Mf/tCckaSRI0eaM6FQyJx5//33zZmhQ4eaM4sWLTJnJKmwsNCcueKKK8yZ3r17mzMnT540Zz766CNzRvI3JNTPz+24cePMGT+/hySppqbGnLF+TY2NjWGt4x4QAMAJCggA4ESHF9Cjjz6qiIiIdjc/72sDAOjZOuUxoDFjxmjDhg3/fxAfb1wGAOjZOqUZ+vTp4+udDgEA3x6d8hhQWVmZ0tPTNWzYMN1+++3au3fvWdc2NTWppqam3Q0A0PN1eAHl5ORoxYoVWrdunZ555hlVVFToqquu0vHjx8+4vqCgQMFgsO2WkZHR0VsCAHRBHV5Aubm5+u53v6tx48Zp9uzZev3111VdXa2XXnrpjOvz8/MVCoXabn6eQw8A6H46/dkB8fHxGjlypHbv3n3GzwcCAV8vTgQAdG+d/jqg2tpalZeXKy0trbMPBQDoRjq8gH7605+qsLBQe/bs0Z///GfddNNN6t27t773ve919KEAAN1Yh/8T3P79+/W9731PR48e1cCBA3XllVequLjY19wwAEDP1eEF9MILL3TI3xMfH28aMHrgwAHzMc72zLzz6dXLfscxPT3dnPEzCLGiosKceeutt8wZSfrZz35mzrz99tvmzIABA8yZJ554wpyRpGnTppkzn332mTlz7Ngxc2b69OnmzKZNm8wZSe1eSB4uP6/98zNYNCcnx5zxM2RWkrZt22bO+Pma/PysFxUVmTOSvwGwzc3NnbKeWXAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4ESnvyGdX/X19fI8L+z1fgaLXn/99eaMpLO+ud65xMXFmTNHjhwxZ/7+7//enLn//vvNGUl66KGHzJmWlhZz5rLLLjNnpk6das5I/oZ3JiUlmTMNDQ3mzHe+8x1z5vnnnzdnJF2wN4m8/fbbzZnS0lJzxu/g4djYWHMmKyvLnPEzxNnvgFU/w32tv4vCvb65BwQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnuuw07FAopKamprDX+5neW1hYaM74VVVVZc58+OGH5ozlnJ127Ngxc0aS+vXrZ87ExMSYM/v37zdnSkpKzBlJKioqMmduueUWc6a+vt6cycvLM2d69+5tzkjSqFGjzJnU1FRzZufOnebMnj17zBk/E+wlKS0tzZz505/+ZM5ER0ebMwcOHDBnJOnQoUPmTGtrq2l9Y2NjWOu4BwQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATnTZYaQDBgwwDa6sqKgwH8PP8ERJqqmpMWf69LGf6ptuusmcaW5uNmcWLlxozkjSpk2bzBk/QzhHjBhhzhw9etSckaTHH3/cnPEzUPOHP/yhOfPuu++aM36uB0nKzMw0Z/74xz+aM9OnTzdnhg0bZs4MHjzYnJGkF1980Zz5u7/7O3PmQg0rlvx9b8MdLnqa53lhreMeEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA40WWHkX7xxRdqaGgIe711WJ7kb0CoJI0cOdKc+eyzz8wZP8MG/ezt6aefNmekUwNjrUKhkDnz8ccfmzPZ2dnmjCStXbvWnPn9739vzkyaNMmc8XON9+3b15yRpK1bt5ozcXFx5kxra6s5c+zYMXNmw4YN5owkjR8/3pzZsWOHORMdHW3O+LVr1y5zJjEx0bS+qakprHXcAwIAOEEBAQCcMBdQUVGRbrjhBqWnpysiIkKvvvpqu897nqeHH35YaWlpiomJ0cyZM1VWVtZR+wUA9BDmAqqrq1N2draWLVt2xs8vXbpUTz/9tJYvX66tW7eqX79+mj17tq9/vwYA9FzmR+Fzc3OVm5t7xs95nqennnpKDz74oG688UZJ0h/+8AelpKTo1Vdf1a233vrNdgsA6DE69DGgiooKVVZWaubMmW0fCwaDysnJ0ZYtW86YaWpqUk1NTbsbAKDn69ACqqyslCSlpKS0+3hKSkrb576qoKBAwWCw7ZaRkdGRWwIAdFHOnwWXn5+vUCjUdtu3b5/rLQEALoAOLaDU1FRJUlVVVbuPV1VVtX3uqwKBgOLi4trdAAA9X4cWUGZmplJTU7Vx48a2j9XU1Gjr1q2aMmVKRx4KANDNmZ8FV1tbq927d7f9uaKiQjt27FBCQoIGDx6sxYsX64knntCIESOUmZmphx56SOnp6Zo7d25H7hsA0M2ZC2jbtm265ppr2v68ZMkSSdL8+fO1YsUK3X///aqrq9PChQtVXV2tK6+8UuvWrbugs44AAF1fhOd5nutNfFlNTY2CwaCefvppxcTEhJ177733zMdKSkoyZyT5eqZe7969zZlDhw6ZM5deeqk5Ex8fb85I0oEDB8yZ5ORkc2b06NHmzNGjR80ZSXrrrbfMmVmzZpkzpaWl5owf//3f/+0r99xzz5kzS5cuNWf8/MvIE088Yc58//vfN2ckacKECeaMn2GkfgaE+n3GcCAQMGcqKipM6xsaGvTAAw8oFAqd83F958+CAwB8O1FAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOCE+e0YLpT6+nq1traGvf673/2u+Rjr1683ZySprKzMnLn44ovNGT9Tqrdt22bONDU1mTOSlJiYaM5s3brVnOnTx36ZvvTSS+aMJJWXl5sz9fX15syAAQPMmcrKSnPmf/7nf8wZSdqzZ485c7Z3PT6Xu+++25zxc90tX77cnJGkf/iHfzBnXn/9dXNm3Lhx5syX35fNws+1FwqFTOsbGxvDWsc9IACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwossOI21qalJERETY6/0MCB0/frw5I0n9+/c3Z2JjY82ZNWvWmDPTp083Z3bs2GHOSNKYMWPMmczMTHOmtLTUnFm8eLE5I4U/RPHL/Ay69HMejh07Zs6888475owkbd682Zy55pprzBk/g1yPHDliztxzzz3mjCStXLnSnMnOzjZnoqOjzZm6ujpzRrIPFpWka6+91rS+rq5Ov/zlL8+7jntAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBElx1GGgwGFRMTE/Z6P4P5IiMjzRnJ35DQq6++2pwZMmSIObNu3TpzZvbs2eaM5G84pp+hscOHDzdn/vjHP5ozkr8BtSNHjjRnEhMTzZn//d//NWeKiorMGcnfz8bPf/5zc+aKK64wZzIyMsyZBQsWmDOSNHDgQHPmyiuvNGdSUlLMGT9DRSXptddeM2csg6Gl8If6cg8IAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJzossNIm5ub1bt377DXl5eXm4/hZ8ilJM2fP9+c6d+/vzmzevVqcyYtLc2ciY+PN2ck6d133zVnamtrzZl+/fqZM34HzfoZausnM2HCBHNm+/bt5ozneeaM5G/A6rhx48yZLVu2mDO/+c1vzJk333zTnJH8DYCdOHGiOfPGG2+YM35NnTrVnLEOIw335497QAAAJyggAIAT5gIqKirSDTfcoPT0dEVEROjVV19t9/k77rhDERER7W5z5szpqP0CAHoIcwHV1dUpOztby5YtO+uaOXPm6NChQ223VatWfaNNAgB6HvOTEHJzc5Wbm3vONYFAQKmpqb43BQDo+TrlMaDNmzcrOTlZo0aN0l133aWjR4+edW1TU5Nqamra3QAAPV+HF9CcOXP0hz/8QRs3btSvfvUrFRYWKjc3VydPnjzj+oKCAgWDwbabn/d7BwB0Px3+OqBbb7217b+zsrI0btw4DR8+XJs3b9aMGTO+tj4/P19Llixp+3NNTQ0lBADfAp3+NOxhw4YpKSlJu3fvPuPnA4GA4uLi2t0AAD1fpxfQ/v37dfToUV+v0AcA9Fzmf4Krra1td2+moqJCO3bsUEJCghISEvTYY49p3rx5Sk1NVXl5ue6//35dfPHFmj17doduHADQvZkLaNu2bbrmmmva/nz68Zv58+frmWeeUWlpqf7zP/9T1dXVSk9P16xZs/T4448rEAh03K4BAN2euYCmT59+zgGHHTVUr76+Xq2trWGvHzp0qPkYe/fuNWck6cMPPzRn6uvrzZmUlBRz5vXXXzdnDh48aM5IUlJSkjlj+Z6e1qeP/bkyfr5Hkr9z7uc1b36+T59++qk5k5ycbM5IOutjtufS3Nxszvi5hhITE82Z9957z5yRTr2kxOq5554zZ6ZMmWLO+LkeJKm6utqcsQ6nbWxsDGsds+AAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgRIe/JXdHiY+PV0xMTNjrBw0aZD5GU1OTOSNJkZGRvnJWfqbWDh8+3Jw5efKkOSNJDQ0N5kyvXvb/5/Ez/fj73/++OSNJoVDInFm3bp0542disp9J4hMnTjRnJKmurs6cKS8vN2cyMjLMmbFjx5ozo0aNMmck6ciRI+aMn6ngH3/8sTlzzz33mDOStGPHDnPm0ksvNa2vra3VL37xi/Ou4x4QAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADjRZYeRtra2moYvvv322+ZjjBs3zpyRpO3bt5sztbW15kxUVJQ542cQ4qOPPmrOSNKTTz5pzvgZRnrgwAFzxs9gTEmaNWuWOVNWVmbO3H///eZMZWWlOeP3Gv/888/NmeXLl5szN954ozkTCATMmUsuucSckaQTJ06YM8OGDTNnRo4cac74HSL87rvvmjPWwcjhDirmHhAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAONFlh5E2Njaa1l9++eXmY/gd5vfwww+bM/n5+eaMn8GdQ4YMMWf27NljzkjSJ598Ys7cc8895kwoFLogx5H8DWb9zW9+Y86sWrXKnMnJyTFn3nzzTXNGklJSUsyZ6667zpy57777zJnrr7/enPnLX/5izkjS3/7t35ozBw8eNGfWrl1rzsydO9eckfx9TdbfEREREWGt4x4QAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADgR4Xme53oTX1ZTU6NgMKj8/HxFR0eHnWttbTUf65JLLjFnJH9DOP1k+vSxz4ptaGgwZ+Li4swZSRozZow5M3DgQHOmrKzMnPFzHiTJz4+Dn2NNmzbNnPnzn/9szliH+p62b98+c2bQoEHmTEVFhTkzfvz4C5KRTv0+snrllVfMmREjRpgzGRkZ5ozk7/dKcXGxaX1LS4v+9Kc/KRQKnfP3C/eAAABOUEAAACdMBVRQUKBJkyYpNjZWycnJmjt3rnbt2tVuTWNjo/Ly8pSYmKj+/ftr3rx5qqqq6tBNAwC6P1MBFRYWKi8vT8XFxVq/fr1aWlo0a9Ys1dXVta2599579dprr+nll19WYWGhDh48qJtvvrnDNw4A6N5Mj0atW7eu3Z9XrFih5ORklZSUaNq0aQqFQvr3f/93rVy5Utdee60k6dlnn9Ull1yi4uJi/c3f/E3H7RwA0K19o8eATr9VckJCgiSppKRELS0tmjlzZtua0aNHa/DgwdqyZcsZ/46mpibV1NS0uwEAej7fBdTa2qrFixdr6tSpGjt2rCSpsrJSUVFRio+Pb7c2JSVFlZWVZ/x7CgoKFAwG225+n1oIAOhefBdQXl6edu7cqRdeeOEbbSA/P1+hUKjt5uf1BwCA7sf+iiRJixYt0tq1a1VUVNTuxWepqalqbm5WdXV1u3tBVVVVSk1NPePfFQgEFAgE/GwDANCNme4BeZ6nRYsWafXq1dq0aZMyMzPbfX7ChAmKjIzUxo0b2z62a9cu7d27V1OmTOmYHQMAegTTPaC8vDytXLlSa9asUWxsbNvjOsFgUDExMQoGg/rxj3+sJUuWKCEhQXFxcbr77rs1ZcoUngEHAGjHVEDPPPOMJGn69OntPv7ss8/qjjvukCT9y7/8i3r16qV58+apqalJs2fP1r/92791yGYBAD2HqYDCGdQYHR2tZcuWadmyZb43JZ0abBgTExP2+mPHjpmP0dLSYs5I0hVXXGHONDU1mTPJycnmzIABA8yZyy+/3JyRpOeee86cOf2MSYtt27ZdkONIUkREhDmzadMmcyYYDJozZ3sm6bk8+uij5owk1dbWmjN+zsN9991nzhw8eNCciY2NNWcknfXlI+dy6623mjNffulKuPwM6ZX8/d6zXnvh/r5jFhwAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCc8PWOqBfC0aNHFR0dHfb6AwcOmI/h9+2/L7vsMnMmKyvLnPEzXfjL70QbrlGjRpkzkjR+/HhzJiUlxZz56hsfhiMhIcGckfxNgZ40aZI542d6+2233WbO+JkcLUnV1dXmjJ8py+vXrzdn/EyJ/+tf/2rOSFJSUpI5c/z4cXOmoqLCnPE7DXvnzp3mzMSJE03r6+vrw1rHPSAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcKLLDiNNSEhQTExM2OtPnDhhPkZqaqo5I0lxcXHmzObNm80Zz/PMmYiICHPm5ZdfNmckKTY21pzp16+fOfPFF1+YM5dffrk5I/kblvrGG2+YMyNGjDBnrr/+enNmz5495owklZaWmjPXXnutOWP5GT/t7bffNmf8DPuU7EM4JX/Dff18TYmJieaM5O/79Omnn5rWNzY2hrWOe0AAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4ESXHUZ6/PhxtbS0hL2+f//+5mPU1dWZM5I0ZMgQc8bP/iZMmGDOHDhwwJwZP368OSNJb775pjnz2muvmTNjxowxZx5//HFzRpJyc3PNmZEjR5oz+/btM2fuu+8+c+Yf//EfzRlJam1tNWe2bt1qztTW1pozSUlJ5kx0dLQ5I536PWTV0NBgzlRXV5szfga5SlJJSYk5M3z4cNP6cM8B94AAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwIkuO4zUKi0tzZxJTU31dazS0lJz5rrrrjNnPvjgA3PmpptuMmcqKyvNGUmaPHmyObNhwwZzxs+w1IEDB5ozkvSXv/zFnPnJT35izvzrv/6rORMVFWXOfPrpp+aMJMXHx5szwWDQnLn66qvNGT/fI78Dd0eNGmXObNu2zZy58sorzZkTJ06YM5I0adIkc8b6NTGMFADQpVFAAAAnTAVUUFCgSZMmKTY2VsnJyZo7d6527drVbs306dMVERHR7nbnnXd26KYBAN2fqYAKCwuVl5en4uJirV+/Xi0tLZo1a9bX3thtwYIFOnToUNtt6dKlHbppAED3Z3oSwrp169r9ecWKFUpOTlZJSYmmTZvW9vG+ffv6foAfAPDt8I0eAwqFQpKkhISEdh9//vnnlZSUpLFjxyo/P1/19fVn/TuamppUU1PT7gYA6Pl8Pw27tbVVixcv1tSpUzV27Ni2j992220aMmSI0tPTVVpaqgceeEC7du3SK6+8csa/p6CgQI899pjfbQAAuinfBZSXl6edO3fqnXfeaffxhQsXtv13VlaW0tLSNGPGDJWXl2v48OFf+3vy8/O1ZMmStj/X1NQoIyPD77YAAN2ErwJatGiR1q5dq6KiIg0aNOica3NyciRJu3fvPmMBBQIBBQIBP9sAAHRjpgLyPE933323Vq9erc2bNyszM/O8mR07dkjyN6kAANBzmQooLy9PK1eu1Jo1axQbG9s2wiUYDComJkbl5eVauXKlrrvuOiUmJqq0tFT33nuvpk2bpnHjxnXKFwAA6J5MBfTMM89IOvVi0y979tlndccddygqKkobNmzQU089pbq6OmVkZGjevHl68MEHO2zDAICewfxPcOeSkZGhwsLCb7QhAMC3Q5edht3Y2Ghaf/o1SRa7d+82ZyR/k4KLi4vNmSNHjpgzX31WYjiysrLMGUmqqqoyZ+bOnWvOnH4c0cLPZGZJGjFihDnjZ/rxwYMHzZkf/OAH5ozfadjn+5/NM6murjZnPv74Y3NmyJAh5oyf3w+S9F//9V/mzBVXXGHOHD582Jzxc+4kf1O0vzxoIBzneu3nlzGMFADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCc6LLDSJOTkxUTExP2+rKyMvMxrrrqKnNGkj777DNzZujQoebM8ePHzZmBAweaMx999JE5I/kbllpTU2PODBgwwJw5/V5VVpGRkebM3r17zZk5c+aYM36+Jr8DK/0cy8/X5Ofc+fke+RkGLPn7ufVzzqOjo82ZM73DdDj8DFO2Ds9taGgIax33gAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBNdbhac53mSwp8ldFpTU5P5WPX19eaMZN+b32NdqK/Jz9cj+dtfa2urOeNnf42NjeaMJJ08efKCHMvP98nP3vx8jySpubnZnPHzNV2oc+fn65H87c/PNX76915nH0eSoqKizBnrz+Dp83a+ryvC8/OVd6L9+/crIyPD9TYAAN/Qvn37NGjQoLN+vssVUGtrqw4ePKjY2FhFRES0+1xNTY0yMjK0b98+xcXFOdqhe5yHUzgPp3AeTuE8nNIVzoPneTp+/LjS09PVq9fZH+npcv8E16tXr3M2piTFxcV9qy+w0zgPp3AeTuE8nMJ5OMX1eQgGg+ddw5MQAABOUEAAACe6VQEFAgE98sgjCgQCrrfiFOfhFM7DKZyHUzgPp3Sn89DlnoQAAPh26Fb3gAAAPQcFBABwggICADhBAQEAnOg2BbRs2TINHTpU0dHRysnJ0Xvvved6Sxfco48+qoiIiHa30aNHu95WpysqKtINN9yg9PR0RURE6NVXX233ec/z9PDDDystLU0xMTGaOXOmysrK3Gy2E53vPNxxxx1fuz7mzJnjZrOdpKCgQJMmTVJsbKySk5M1d+5c7dq1q92axsZG5eXlKTExUf3799e8efNUVVXlaMedI5zzMH369K9dD3feeaejHZ9ZtyigF198UUuWLNEjjzyiDz74QNnZ2Zo9e7YOHz7semsX3JgxY3To0KG22zvvvON6S52urq5O2dnZWrZs2Rk/v3TpUj399NNavny5tm7dqn79+mn27Nm+B5J2Vec7D5I0Z86cdtfHqlWrLuAOO19hYaHy8vJUXFys9evXq6WlRbNmzVJdXV3bmnvvvVevvfaaXn75ZRUWFurgwYO6+eabHe6644VzHiRpwYIF7a6HpUuXOtrxWXjdwOTJk728vLy2P588edJLT0/3CgoKHO7qwnvkkUe87Oxs19twSpK3evXqtj+3trZ6qamp3q9//eu2j1VXV3uBQMBbtWqVgx1eGF89D57nefPnz/duvPFGJ/tx5fDhw54kr7Cw0PO8U9/7yMhI7+WXX25b89FHH3mSvC1btrjaZqf76nnwPM+7+uqrvXvuucfdpsLQ5e8BNTc3q6SkRDNnzmz7WK9evTRz5kxt2bLF4c7cKCsrU3p6uoYNG6bbb79de/fudb0lpyoqKlRZWdnu+ggGg8rJyflWXh+bN29WcnKyRo0apbvuuktHjx51vaVOFQqFJEkJCQmSpJKSErW0tLS7HkaPHq3Bgwf36Ovhq+fhtOeff15JSUkaO3as8vPzfb8FTWfpcsNIv+rIkSM6efKkUlJS2n08JSVFH3/8saNduZGTk6MVK1Zo1KhROnTokB577DFdddVV2rlzp2JjY11vz4nKykpJOuP1cfpz3xZz5szRzTffrMzMTJWXl+vnP/+5cnNztWXLFvXu3dv19jpca2urFi9erKlTp2rs2LGSTl0PUVFRio+Pb7e2J18PZzoPknTbbbdpyJAhSk9PV2lpqR544AHt2rVLr7zyisPdttflCwj/Lzc3t+2/x40bp5ycHA0ZMkQvvfSSfvzjHzvcGbqCW2+9te2/s7KyNG7cOA0fPlybN2/WjBkzHO6sc+Tl5Wnnzp3fisdBz+Vs52HhwoVt/52VlaW0tDTNmDFD5eXlGj58+IXe5hl1+X+CS0pKUu/evb/2LJaqqiqlpqY62lXXEB8fr5EjR2r37t2ut+LM6WuA6+Prhg0bpqSkpB55fSxatEhr167VW2+91e7tW1JTU9Xc3Kzq6up263vq9XC283AmOTk5ktSlrocuX0BRUVGaMGGCNm7c2Pax1tZWbdy4UVOmTHG4M/dqa2tVXl6utLQ011txJjMzU6mpqe2uj5qaGm3duvVbf33s379fR48e7VHXh+d5WrRokVavXq1NmzYpMzOz3ecnTJigyMjIdtfDrl27tHfv3h51PZzvPJzJjh07JKlrXQ+unwURjhdeeMELBALeihUrvL/+9a/ewoULvfj4eK+ystL11i6on/zkJ97mzZu9iooK79133/VmzpzpJSUleYcPH3a9tU51/Phxb/v27d727ds9Sd6TTz7pbd++3fvss888z/O8f/7nf/bi4+O9NWvWeKWlpd6NN97oZWZmeg0NDY533rHOdR6OHz/u/fSnP/W2bNniVVRUeBs2bPDGjx/vjRgxwmtsbHS99Q5z1113ecFg0Nu8ebN36NChtlt9fX3bmjvvvNMbPHiwt2nTJm/btm3elClTvClTpjjcdcc733nYvXu394tf/MLbtm2bV1FR4a1Zs8YbNmyYN23aNMc7b69bFJDned5vf/tbb/DgwV5UVJQ3efJkr7i42PWWLrhbbrnFS0tL86KioryLLrrIu+WWW7zdu3e73lane+uttzxJX7vNnz/f87xTT8V+6KGHvJSUFC8QCHgzZszwdu3a5XbTneBc56G+vt6bNWuWN3DgQC8yMtIbMmSIt2DBgh73P2ln+volec8++2zbmoaGBu+f/umfvAEDBnh9+/b1brrpJu/QoUPuNt0Jznce9u7d602bNs1LSEjwAoGAd/HFF3v33XefFwqF3G78K3g7BgCAE13+MSAAQM9EAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACf+D+W+Et7T5/JLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "  #Step 1:\n",
        "  network = tf.keras.Sequential()     # default class to buid neural network using Tenserflow\n",
        "\n",
        "  #Step 2: to downscale cnn layer using Conv2D\n",
        "\n",
        "  # 14*14*64\n",
        "  network.add(layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', strides = (2,2), input_shape = [28,28,1] ))\n",
        "  network.add(layers.LeakyReLU())\n",
        "  network.add(layers.Dropout(0.3))     #dropout done to avoid obverfitting in neural net\n",
        "\n",
        "  #7*7*128\n",
        "  network.add(layers.Conv2D(filters=128, kernel_size=(5,5), padding='same', strides = (2,2) ))\n",
        "  network.add(layers.LeakyReLU())\n",
        "  network.add(layers.Dropout(0.3))\n",
        "\n",
        "  #converting matrix to vector\n",
        "  network.add(layers.Flatten())\n",
        "\n",
        "  #next to use only 1 neron for output\n",
        "  network.add(layers.Dense(1))\n",
        "\n",
        "  network.summary()\n",
        "  return network"
      ],
      "metadata": {
        "id": "619dJLgAlzDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator=  build_discriminator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9ZsSl7WtTnT",
        "outputId": "a791a303-abba-4fb5-b503-306410d0b562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 14, 14, 64)        1664      \n",
            "                                                                 \n",
            " leaky_re_lu_22 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "                                                                 \n",
            " leaky_re_lu_23 (LeakyReLU)  (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212865 (831.50 KB)\n",
            "Trainable params: 212865 (831.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNdMCcz8tgOQ",
        "outputId": "8223297f-e2bf-499e-d648-70bf75c91741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 28, 28, 1) dtype=float32 (created by layer 'conv2d_8_input')>"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator(generated_image, training=False)  #here we test discriminator with image generated by generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-BuU-RxvcHE",
        "outputId": "50cc0ecd-3a58-4cc7-f401-b55a3b127ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.00300417]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we apply activation function to translate it to probabilities"
      ],
      "metadata": {
        "id": "jctF8XTWwPq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.sigmoid(-0.00285281)   #output gives 0.49 ie 50% probability for image to be right"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOt8GSg3vqFz",
        "outputId": "e14a5f84-5802-4cd8-92c6-d3f8e3e4ad69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.4992868>"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)"
      ],
      "metadata": {
        "id": "YFKpO5ouvwLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(expected_output, fake_output):\n",
        "  #compute the loss for real images by comparing them to a tensor of ones(real labels).\n",
        "  real_loss= cross_entropy(tf.ones_like(expected_output), expected_output)\n",
        "  #since real images are equivalent to one. For this reason, we are comparing the expected outputs , the real images with number ones.\n",
        "  fake_loss=cross_entropy(tf.zeroes_like(fake_output), fake_output)\n",
        "  #calculate the total discriminator loss by summing the real and fake losses.\n",
        "  total_loss= real_loss + fake_loss\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "3AeJiP6bwLag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "zKz0B3xnzFRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "discriminator_optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001)"
      ],
      "metadata": {
        "id": "3pNC2klv0QyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 100\n",
        "noise_dimension= 100\n",
        "number_of_images= 16"
      ],
      "metadata": {
        "id": "oLDX1Ny90z8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, noise_dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jVoaxGA1Nro",
        "outputId": "0d810d44-26d9-4a5d-d710-0930a1e20619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train(images):\n",
        "  noise = tf.random.normal([batch_size, noise_dimension])\n",
        "\n",
        "  # gradient calc\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "\n",
        "    #generate fake imgs\n",
        "    generated_images = generator(noise, training=True)\n",
        "\n",
        "    #calc disc output\n",
        "    expected_output = discriminator(images, training = True)\n",
        "    fake_output = discriminator(generated_images, training = True)\n",
        "\n",
        "    #calc losses\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(expected_output, fake_output)\n",
        "\n",
        "    #gradient cal\n",
        "    gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    #application of gradient using optimizer\n",
        "    generator_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "dPRjNpXQ1SnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTX4rXvc9VDS",
        "outputId": "ec862362-4b38-40f5-c8d3-eff6ca6aec0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "X_train_batch = X_train.as_numpy_iterator().next()\n",
        "train(X_train_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "Ztnmtzp85dA0",
        "outputId": "eee00b5f-dae0-48ad-811b-93cbb0309ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'as_numpy_iterator'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-211-f0cfd176adc2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_functions_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'as_numpy_iterator'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = tf.random.normal([number_of_images, noise_dimension])\n",
        "test_images.shape"
      ],
      "metadata": {
        "id": "v3hnojyo5iUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "60000 / 256"
      ],
      "metadata": {
        "id": "XhTomE865frJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_images =[]\n",
        "def train_gan(dataset, epochs, test_images):\n",
        "  for epoch in range(epochs):\n",
        "    #print(epoch)\n",
        "    for image_batch in dataset:\n",
        "      #print(image_batch.shape)\n",
        "      train(image_batch)\n",
        "\n",
        "    print('Epoch: ', epoch + 1)\n",
        "    generated_images = generator(test_images, training = False)\n",
        "    fig = plt.figure(figsize = (10,10))\n",
        "    for i in range(generated_images.shape[0]):\n",
        "      plt.subplot(4,4,i + 1)  # The subplot method has 3 arguments: rows, columns and index of the current plot.\n",
        "      plt.imshow(generated_images[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "d7J6Ah-f65uO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gan(X_train, epochs, test_images)"
      ],
      "metadata": {
        "id": "FH0fEAhn69V-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}